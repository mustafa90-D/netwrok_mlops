### Network Security Projects For Phising Data

Setup github secrets:
AWS_ACCESS_KEY_ID=

AWS_SECRET_ACCESS_KEY=

AWS_REGION = us-east-1

AWS_ECR_LOGIN_URI = 788614365622.dkr.ecr.us-east-1.amazonaws.com/networkssecurity
ECR_REPOSITORY_NAME = networkssecurity


Docker Setup In EC2 commands to be Executed
#optinal

sudo apt-get update -y

sudo apt-get upgrade

#required

curl -fsSL https://get.docker.com -o get-docker.sh


sudo sh get-docker.sh

sudo usermod -aG docker ubuntu


newgrp docker

# ğŸ›¡ï¸ Network Security Threat Detection with MLOps

This project is a modular, production-ready **MLOps pipeline** for detecting network security threats such as phishing, anomalies, and malicious behaviors. It leverages a scalable architecture and integrates **ETL, model training, validation, prediction, logging, cloud sync, CI/CD**, and **MongoDB** for storing results or metadata.

---

## ğŸ“Œ Project Goals

- Detect and classify threats in network data
- Enable automated training, validation, and prediction
- Follow **MLOps best practices** with modular architecture
- Make the system deployable and maintainable using CI/CD, logging, and configuration management

---

## ğŸ—‚ï¸ Project Structure

```
MLOPS/
â”‚
â”œâ”€â”€ Artifacts/                     # Stores models, logs, and outputs
â”œâ”€â”€ data_schema/                  # YAML schema for data validation
â”‚   â””â”€â”€ schema.yaml
â”œâ”€â”€ logs/                         # Logs from all stages
â”œâ”€â”€ Network_Data/                 # Raw CSV dataset
â”‚   â””â”€â”€ phishingData.csv
â”œâ”€â”€ networksecurity/              # Main Python package
â”‚   â”œâ”€â”€ cloud/                   # S3 Sync utility
â”‚   â”œâ”€â”€ components/             # Ingestion, transformation, trainer
â”‚   â”œâ”€â”€ constant/               # Constants
â”‚   â”œâ”€â”€ entity/                 # Pydantic-based config and output schemas
â”‚   â”œâ”€â”€ exception/              # Custom exception handling
â”‚   â”œâ”€â”€ logging/                # Central logger
â”‚   â”œâ”€â”€ pipeline/               # Training + Batch prediction scripts
â”‚   â”œâ”€â”€ utils/                  # Helper methods (file ops, etc.)
â”‚   â””â”€â”€ main_utils/ml_utils/    # Metrics, estimators, model logic
â”œâ”€â”€ prediction_output/           # Generated predictions
â”œâ”€â”€ templates/                   # UI if any
â”œâ”€â”€ valid_data/                  # Cleaned/validated data
â”œâ”€â”€ .env                         # Environment config
â”œâ”€â”€ Dockerfile                   # Container setup
â”œâ”€â”€ push_data.py                 # Script to push to MongoDB
â”œâ”€â”€ test_mongodb.py              # MongoDB testing
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ setup.py                     # Installable module
â”œâ”€â”€ main.py                      # Launch entry point
â”œâ”€â”€ app.py                       # Streamlit or FastAPI app
â””â”€â”€ README.md
```

---

## ğŸ”„ MLOps Pipeline Stages

| Stage                  | Description |
|------------------------|-------------|
| `data_ingestion.py`    | Downloads and loads the raw phishing/network data |
| `data_validation.py`   | Validates CSV against `schema.yaml` |
| `data_transformation.py` | Prepares data for modeling |
| `model_trainer.py`     | Trains a classifier (e.g., RandomForest, XGBoost) |
| `batch_prediction.py`  | Makes predictions on unseen/new data |
| `s3_syncer.py`         | Sync artifacts with AWS S3 |
| `push_data.py`         | Pushes metadata or results to MongoDB |

---

## ğŸ§ª Technologies Used

-ğŸ“¦ ML libraries (Scikit-learn, LightGBM, XGBoost)

â˜ï¸ Cloud tools (AWS S3)

ğŸ§  Tracking (MLflow)

ğŸ§± Infrastructure (Docker, CI/CD, MongoDB)

ğŸ–¥ï¸ Serving (Streamlit or FastAPI)

âš™ï¸ Utilities (PyYAML, logging, GitHub Actions)

---

## âœ… CI/CD Integration

- **CI**: Code is linted, tested, and validated on every push via GitHub Actions
- **CD**: Artifacts can be deployed to cloud storage or app platforms

---

## ğŸ“Š MongoDB Integration

Prediction logs or performance metrics can be pushed to **MongoDB Atlas** or local instance using `push_data.py`.

You can easily switch or expand to any other NoSQL database with `pymongo`.

---

## ğŸš€ Future Work

- Add alert generation system
- Integrate with real-time network data APIs
- Improve model explainability with SHAP or LIME
- Enhance Streamlit/FastAPI dashboards

---

## ğŸ‘¨â€ğŸ’» Author

Made with â¤ï¸ by Mustafa  
_â€œBuilt with modularity, powered by MLOps.â€_

---

